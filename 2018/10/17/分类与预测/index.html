<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="数据挖掘 数据分析 分类回归 ML," />










<meta name="description" content="分类即构造一个分类模型，将每个样本映射到预先定义好的类别，输入样本的属性特征，输出类别。分类模型建立在已有类标的数据集上，属于有监督的学习。    下图是分类算法与分类模型的过程。预测模型与之相似，首先通过训练机建立预测属性的函数模型，然后在模型通过检验后进行预测或控制。 常用的分类与预测算法 回归分析 决策树 人工神经网络 贝叶斯网络 支持向量机  回归分析回归分析是确定两种或两种以上变量间相互">
<meta name="keywords" content="数据挖掘 数据分析 分类回归 ML">
<meta property="og:type" content="article">
<meta property="og:title" content="分类与预测之回归分析">
<meta property="og:url" content="http://yoursite.com/2018/10/17/分类与预测/index.html">
<meta property="og:site_name" content="国民大可爱、">
<meta property="og:description" content="分类即构造一个分类模型，将每个样本映射到预先定义好的类别，输入样本的属性特征，输出类别。分类模型建立在已有类标的数据集上，属于有监督的学习。    下图是分类算法与分类模型的过程。预测模型与之相似，首先通过训练机建立预测属性的函数模型，然后在模型通过检验后进行预测或控制。 常用的分类与预测算法 回归分析 决策树 人工神经网络 贝叶斯网络 支持向量机  回归分析回归分析是确定两种或两种以上变量间相互">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2018/10/17/分类与预测/分类模型的实现步骤.png">
<meta property="og:image" content="http://yoursite.com/2018/10/17/分类与预测/Logistic.png">
<meta property="og:image" content="http://yoursite.com/2018/10/17/分类与预测/银行贷款数据.jpg">
<meta property="og:image" content="http://yoursite.com/2018/10/17/分类与预测/银行代码结果.jpg">
<meta property="og:updated_time" content="2018-10-20T06:48:53.812Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分类与预测之回归分析">
<meta name="twitter:description" content="分类即构造一个分类模型，将每个样本映射到预先定义好的类别，输入样本的属性特征，输出类别。分类模型建立在已有类标的数据集上，属于有监督的学习。    下图是分类算法与分类模型的过程。预测模型与之相似，首先通过训练机建立预测属性的函数模型，然后在模型通过检验后进行预测或控制。 常用的分类与预测算法 回归分析 决策树 人工神经网络 贝叶斯网络 支持向量机  回归分析回归分析是确定两种或两种以上变量间相互">
<meta name="twitter:image" content="http://yoursite.com/2018/10/17/分类与预测/分类模型的实现步骤.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/10/17/分类与预测/"/>





  <title>分类与预测之回归分析 | 国民大可爱、</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">国民大可爱、</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Book思议在划水</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/17/分类与预测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen Zhaoyun">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="国民大可爱、">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">分类与预测之回归分析</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-17T19:34:08+08:00">
                2018-10-17
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/17/分类与预测/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2018/10/17/分类与预测/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p>即构造一个分类模型，将每个样本映射到预先定义好的类别，输入样本的属性特征，输出类别。<br>分类模型建立在已有类标的数据集上，属于有监督的学习。<br>    下图是分类算法与分类模型的过程。预测模型与之相似，首先通过训练机建立预测属性的函数模型，然后在模型通过检验后进行预测或控制。<br><img src="/2018/10/17/分类与预测/分类模型的实现步骤.png" alt=""></p>
<h2 id="常用的分类与预测算法"><a href="#常用的分类与预测算法" class="headerlink" title="常用的分类与预测算法"></a>常用的分类与预测算法</h2><ul>
<li>回归分析</li>
<li>决策树</li>
<li>人工神经网络</li>
<li>贝叶斯网络</li>
<li>支持向量机</li>
</ul>
<h1 id="回归分析"><a href="#回归分析" class="headerlink" title="回归分析"></a>回归分析</h1><p>回归分析是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，在图像上表现为一条努力拟合所有数据点的曲线/线段，其目标是使数据点和曲线间的距离最小化。<br>回归分析的优点有很多，主要表现在：<br>    1.能显示因变量和自变量之间的显著关系；<br>    2.能表现多个独立变量对因变量对不同影响程度。</p>
<p>常见的回归模型如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>回归模型</th>
<th style="text-align:center">适用条件</th>
</tr>
</thead>
<tbody>
<tr>
<td>线性回归</td>
<td style="text-align:center">因变量与自变量是线性关系</td>
</tr>
<tr>
<td>非线性回归</td>
<td style="text-align:center">因变量与自变量之间不都是线性关系</td>
</tr>
<tr>
<td>Logistic回归</td>
<td style="text-align:center">因变量一般有1和0(是否)两种取值</td>
</tr>
<tr>
<td>岭回归</td>
<td style="text-align:center">参与建模的自变量之间具有多重共线性</td>
</tr>
<tr>
<td>主成分回归</td>
<td style="text-align:center">参与建模的自变量之间具有多重共线性</td>
</tr>
</tbody>
</table>
</div>
<p>此外，还有Lasso回归、ElasticNet回归等模型</p>
<h2 id="线性回归-Linear-Regression"><a href="#线性回归-Linear-Regression" class="headerlink" title="线性回归 Linear Regression"></a>线性回归 Linear Regression</h2><p>线性回归采用一条拟合直线在因变量(Y)和一个或多个自变量(X)之间建立关系：</p>
<script type="math/tex; mode=display">Y=\theta^X</script><p>回归就是求解回归系数$\theta$,一般有最小二乘法、梯度下降来求解。</p>
<h2 id="Logistic回归"><a href="#Logistic回归" class="headerlink" title="Logistic回归"></a>Logistic回归</h2><p>LR模型中的因变量只有1-0(是-否、发生-不发生)两种取值。</p>
<h3 id="Logistic函数"><a href="#Logistic函数" class="headerlink" title="Logistic函数"></a>Logistic函数</h3><p>假设在$p$个独立变量$x_1,x_2,…,x_p$作用下，$y$取1的概率是$p$，取0的概率是$1-p$,两种取值的概率比为$\frac{p}{1-p}$,被称为事件的优势比(odds)，对其取自然对数就是Logistic变换：<script type="math/tex">Logit(p) = ln(\frac{p}{1-p})</script><br>令$Logit(p)=z$,那么$p=\frac{1}{1+e^{-z}}$就是Logistic函数，如下图所示：<br><img src="/2018/10/17/分类与预测/Logistic.png" alt=""></p>
<h3 id="Logistic回归模型"><a href="#Logistic回归模型" class="headerlink" title="Logistic回归模型"></a>Logistic回归模型</h3><p>Logistic回归模型为：<script type="math/tex">ln(\frac{p}{1-p}=\beta_0+\beta_1x_1+...+\beta_px_p+\epsilon)</script></p>
<h3 id="Logistic回归建模"><a href="#Logistic回归建模" class="headerlink" title="Logistic回归建模"></a>Logistic回归建模</h3><p>step1:根据挖掘目的设置特征(因变量和自变量)，收集数据并筛选特征；<br>step2:$y$取1的概率是$p$，取0的概率是$1-p$,列出回归方程$ln(\frac{p}{1-p}=\beta_0+\beta_1x_1+…+\beta_px_p+\epsilon)$，并估计回归系数；<br>step3:进行模型检验，正确率、混淆矩阵、ROC曲线、KS值等；<br>step4:模型应用：输入自变量得到预测变量的值，或根据预测变量的值控制自变量的值。</p>
<h3 id="实例：降低银行贷款拖欠率"><a href="#实例：降低银行贷款拖欠率" class="headerlink" title="实例：降低银行贷款拖欠率"></a>实例：降低银行贷款拖欠率</h3><p>部分银行贷款拖欠率数据如下图：<br><img src="/2018/10/17/分类与预测/银行贷款数据.jpg" alt=""><br>使用Scikit-Learn对该数据进行Logistic回归分析。<br>首先进行特征筛选：特征筛选主要包含在Scikit_Learn的feature_selection库中</p>
<ul>
<li>通过F检验(f_regression)给出各个特征的F值和P值，从而筛选变量(选择F值较大的或P值小的)</li>
<li>递归特征消除(Recursive Feature Elimination,RFE)</li>
<li>稳定性选择</li>
</ul>
<p>这里采用<strong>稳定性选择</strong>的方法进行特征筛选，然后用筛选后的特征建立Logistic模型，并输出平均正确率。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*—</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data_path = <span class="string">'/data/bankloan.xls'</span></span><br><span class="line">data = pd.read_excel(data_path)</span><br><span class="line">x = data.iloc[:,:<span class="number">8</span>].as_matrix()<span class="comment">#数据前8列是特征</span></span><br><span class="line">y = data.iloc[:,<span class="number">8</span>].as_matrix()<span class="comment">#数据第8列是标签</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="keyword">as</span> LR</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RandomizedLogisticRegression <span class="keyword">as</span> RLR</span><br><span class="line">rlr = RLR()<span class="comment">#建立随机逻辑回归模型，筛选变量，默认selection_threshold=0.25</span></span><br><span class="line">rlr.fit(x,y)<span class="comment">#训练模型</span></span><br><span class="line">rlr.get_support()<span class="comment">#获取特征筛选结果</span></span><br><span class="line"><span class="comment">#a = rlr.scores_ #也可以用.scores来获取各个特征的分数</span></span><br><span class="line">print(<span class="string">'--- 稳定性选择法-筛选特征已完成 ---'</span>)</span><br><span class="line"><span class="comment">#'numpy.ndarray' object has no attribute 'columns'</span></span><br><span class="line"><span class="comment">#所以不能采用x.columns[rlr.get_support()]</span></span><br><span class="line">print(<span class="string">'有效特征为：%s'</span> % <span class="string">','</span>.join(data.iloc[:,:<span class="number">8</span>].columns[rlr.get_support()]))</span><br><span class="line">x = data[data.iloc[:,:<span class="number">8</span>].columns[rlr.get_support()]].as_matrix()<span class="comment">#特征筛选后的x</span></span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">lr = LR()<span class="comment">#建立逻辑回归模型</span></span><br><span class="line">lr.fit(x,y)<span class="comment">#用筛选后的特征来训练模型</span></span><br><span class="line">print(<span class="string">'--- 逻辑回归模型训练结束 ---'</span>)</span><br><span class="line">print(<span class="string">'模型的平均正确率为：%s'</span> % lr.score(x,y))</span><br></pre></td></tr></table></figure></p>
<p>关于代码的解读已经打在注释里了，这里主要说明一下RLR一般被认为是属于<strong>维度规约</strong>的算法类，不属于常说的分类算法的范畴。<br>输出结果如图：<br><img src="/2018/10/17/分类与预测/银行代码结果.jpg" alt=""><br>看到过这么一句话：<br>    数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限。<br>可见特征的选择是一件重要的事情，减少特征数量并降维使得模型泛化能力更强并增强特征和特征值之间的理解。下面主要来讲一讲特征筛选。<br>训练模型时，我们要选择有意义的特征，主要从以下两方面进行考虑：<br>1.特征是否发散：如果特征不发散，比如方差接近0，那么可以认为样本在该特征上无差异，该特征对于区分样本是没有用的。<br>2.特征与目标的相关性：即选择与目标相关性高的特征。<br>根据特征选择的形式可以将特征选择法分为3种：Filter过滤法、Wrapper包装法、Embedded嵌入法。<br>1.Filter：按照发散性或相关性对各个特征进行评分，设定阈值或待选择阈值的个数来选择特征。</p>
<ul>
<li>去掉取值变化小的特征</li>
</ul>
<p>非常简单的方法，简单的说就是如果一个特征的特征值只有0和1，并且大部分或者全部都是1，那么就可以认为该特征没有什么作用(如果是连续型变量，则要先离散化)，但这种情况其实很少出现，所以该方法不太常用，一般作为特征选择的预处理，方便后续特征筛选。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold <span class="keyword">as</span> VT</span><br><span class="line">VT(threshold = <span class="number">3</span>).fit_transform(data) <span class="comment">#threshold为方差的阈值</span></span><br><span class="line"><span class="comment">#返回值为特征选择后的数据</span></span><br></pre></td></tr></table></figure>
<pre><code>Tip：在这里我想简单的说一下sklearn中fit_transform()和transform()的区别
两者都是对数据作某种统一处理，fit_transform(partData)是对数据先进行**拟合**，然后再作归一化处理；
fit完数据后，transform(restData)，那么rest和part是按照同一标准进行数据处理的；
如果是fit_transform(partData),虽然也能做数据处理，但是与partData的处理不在相同标准下，处理完后会有明显差异；
如果没有fit，直接transform(partData),则会报错。
</code></pre><ul>
<li>单变量特征选择</li>
</ul>
<p>对每个特征进行测试，衡量该特征和特征值之间的关系，根据评分去掉不好的特征。这种方法<strong>简单便于理解</strong>，但对于特征优化、提高模型泛化能力不一定有效。<br>对于分类问题(y离散)，可采用：卡方检验、f_classif、mutual_info_classif、互信息<br>对于回归问题(y连续)，可采用：皮尔森相关系数、f_regression、mutual_info_regression、最大信息系数<br>Pearson相关系数：<strong>最简单</strong>，帮助计算各个特征对目标值的相关系数以及相关系数的P值，衡量变量之间的线性相关性，结果取值$[-1,1]$,-1表示完全负相关、+1表示完全正相关、0表示没有线性相关。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest<span class="comment">#只保留K个最高分的特征</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectPercentile<span class="comment">#只保留用户指定百分比的最高得分的特征</span></span><br><span class="line"><span class="comment">#from sklearn.feature_selection import chi2#卡方检验</span></span><br><span class="line"><span class="comment">#from scipy.stats import pearsonr</span></span><br><span class="line"><span class="comment">#SelectKBest和SelectPerecntile能够返回特征评价的得分和P值</span></span><br><span class="line">x = SelectKBest(score_fun,k=<span class="number">2</span>).fit_transform(data,target)<span class="comment">#K值自己设，percentile值也是自己设定</span></span><br><span class="line">x = SelectPercentile(score_fun,percentile = <span class="number">10</span>)<span class="comment">#score_fun为评分函数，例如卡方检验chi2等，具体的上文已经给出</span></span><br><span class="line"><span class="comment">#卡方检验</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line">x_new = SelectKBest(chi2,k=<span class="number">2</span>).fit_transform(x,y)<span class="comment">#这时x变为两个特征</span></span><br><span class="line"><span class="comment">#皮尔森相关系数:要求变量变化关系单调</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="comment">#pearsonr(x,y)的输入为特征矩阵和目标向量</span></span><br><span class="line">pearson(X,Y) <span class="comment">#输出为二元组(score,p-value)的数组</span></span><br><span class="line"><span class="comment">#SelectKBest(lambda X, Y: array(map(lambda x:pearsonr(x, Y), X.T)).T, k=2).fit_transform(data,target)</span></span><br><span class="line"><span class="comment">#互信息法:评价定性自变量对定性因变量的相关性</span></span><br><span class="line"><span class="keyword">from</span> minepy <span class="keyword">import</span> MINE</span><br><span class="line">m = MINE()</span><br><span class="line">m.compute_score(x,y)</span><br><span class="line">m.mic()</span><br></pre></td></tr></table></figure></p>
<p>2.Wrapper:根据目标函数(一般是预测效果评分)，每次选择若干特征，或排除若干特征。<br>递归特征消除RFE：使用一个基模型来进行多轮训练，每轮训练后，移除若干权值系数的特征，再基于新的特征集进行下一轮训练</p>
<pre><code>递归特征消除的主要思想时反复的构建模(SVM、回归模型等)。
选出最好的(或最差的)特征，把选出来的特征放在一边，在剩余特征上重复该过程，遍历所有特征。
该过程中特征被消除的次序就是特征的排序。
Scikit-Learn中提供了RFE、RFECV,可以进行交叉验证。
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#estimator为基模型，这里为LR模型</span></span><br><span class="line"><span class="comment">#返回特征选择后的数据</span></span><br><span class="line">RFE(estimator = LogisticRegression(),n_feature_to_select = <span class="number">2</span>).fit_transform(data,target)</span><br></pre></td></tr></table></figure>
<p>3.Embedded:根据ML的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征，与Filter法类似，只不过是根据模型训练来选择特征。<br>SelectFromModel：能够用于拟合后任何拥有coef_或feature_importances_ 属性的预测模型。 如果特征对应的coef_ 或 feature_importances_ 值低于设定的阈值threshold，那么这些特征将被移除。</p>
<p>基于L1范数的特征选择：使用L1范数作为惩罚项的线性模型(Linear models)会得到稀疏解：大部分特征对应的系数为0。当你希望减少特征的维度以用于其它分类器时，可以通过feature_selection.SelectFromModel 来选择不为0的系数。<br><strong>linear_model.Lasso(回归)</strong>、<strong>linear_model.LogisticRegression</strong>和<strong>svm.LinearSVC(分类)</strong>这些模型较为常用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line">iris = load_iris()</span><br><span class="line">x,y = iris.data,iris.target</span><br><span class="line"></span><br><span class="line">SelectModel(LinearSVC(penalty = <span class="string">'l1'</span>,c = <span class="number">0.01</span>)).fit_transform(x,y)</span><br><span class="line"><span class="comment">#lsvc = LinearSVC(c = 0.01,penalty = 'l1',dual  = False).fit(x,y) #C越小，被选中的特征越少</span></span><br><span class="line"><span class="comment">#model  = SelectFromModel(lsvc,prefit = True)</span></span><br><span class="line"><span class="comment">#x_new = model.transform(x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#带L1惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">SelectModel(LogisticRegression(penalty = <span class="string">'l1'</span>,c = <span class="number">0.1</span>)).fit_transform(x,y)</span><br></pre></td></tr></table></figure></p>
<p>但是，该方法存在局限性：如果两个特征相关时，只会选择其中一个特征。</p>
<p>随机稀疏模型：为了解决上述问题，可以使用sklearn.linear_model中的stability selection这种随机化方法。在stability selection(<strong>稳定性选择</strong>)中，使用数据的子集去拟合模型，系数的随机子集的罚项将被小。</p>
<pre><code>稳定性选择是一种基于二次抽样和选择算法(回归、SVM等)相结合的较新方法。
主要思想时在不同数据子集和特征子集上运行特征选择算法，不断重复，最紫红汇总特征选择结果。
理想特征得分接近100%，无用特征接近0。
Scikit-Learn在Lasso和RLR中都有稳定性选择的实现。
</code></pre><p>基于决策树的特征选择:可以算特征的重要程度，所以反过来也可以去除不相关的特征<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line">iris = load_iris()</span><br><span class="line">x,y = iris.data,iris.target</span><br><span class="line"><span class="comment">#print(x.shape) #(150,4)</span></span><br><span class="line">clf = ExtraTreesClassifier()</span><br><span class="line">clf = clf.fit(x,y)</span><br><span class="line"><span class="comment">#print(clf.feature_importances_) #[0.04973085 0.05026085 0.49297071 0.4070376 ]</span></span><br><span class="line">model = SelectFromModel(clf,prefit = true)</span><br><span class="line">x_new = model.transform(x)</span><br><span class="line"><span class="comment">#print(x.shape) #(150,2)</span></span><br></pre></td></tr></table></figure></p>
<p><strong>逻辑回归本质上依然属于线性模型，被筛选掉的特征只是与结果不具有较强的线性关系而已，可能会具有非线性关系，具体问题具体分析。<br>对于非线性变量的筛选可以依靠决策树、神经网络等</strong></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/数据挖掘-数据分析-分类回归-ML/" rel="tag"># 数据挖掘 数据分析 分类回归 ML</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/10/16/聚类算法/" rel="next" title="聚类算法">
                <i class="fa fa-chevron-left"></i> 聚类算法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/10/20/回归分析之决策树/" rel="prev" title="回归分析之决策树">
                回归分析之决策树 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Chen Zhaoyun" />
            
              <p class="site-author-name" itemprop="name">Chen Zhaoyun</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#分类"><span class="nav-number">1.</span> <span class="nav-text">分类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#常用的分类与预测算法"><span class="nav-number">1.1.</span> <span class="nav-text">常用的分类与预测算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#回归分析"><span class="nav-number">2.</span> <span class="nav-text">回归分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性回归-Linear-Regression"><span class="nav-number">2.1.</span> <span class="nav-text">线性回归 Linear Regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistic回归"><span class="nav-number">2.2.</span> <span class="nav-text">Logistic回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Logistic函数"><span class="nav-number">2.2.1.</span> <span class="nav-text">Logistic函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Logistic回归模型"><span class="nav-number">2.2.2.</span> <span class="nav-text">Logistic回归模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Logistic回归建模"><span class="nav-number">2.2.3.</span> <span class="nav-text">Logistic回归建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实例：降低银行贷款拖欠率"><span class="nav-number">2.2.4.</span> <span class="nav-text">实例：降低银行贷款拖欠率</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen Zhaoyun</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'KSn8wT5RN2dHd9qrxrtR3e0g-gzGzoHsz',
        appKey: 'DezWAMrdLtNBOzESQv1mlViN',
        placeholder: '你也上网冲浪呀',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
